{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验说明\n",
    "\n",
    "## 作业说明\n",
    "\n",
    "### 目标：\n",
    "\n",
    "训练一个玩2048的神经网络，并得到较高的准确率。\n",
    "\n",
    "### 背景：\n",
    "\n",
    "2048是一个益智小游戏，规则为：控制所有方块向同一个方向运动，两个相同数字方块撞在一起后合并，成为他们的和。每次操作时会随机生成一个2或者4，最终得到一个“2048”的方块就算胜利。规则的直观解释：[Click to Play 2048](https://play2048.co/)\n",
    "\n",
    "本教程展示如何训练一个玩2048的神经网络模型，并评估其最终能够得到的分数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建模过程：\n",
    "\n",
    "2048游戏可以理解为一个这样的过程：\n",
    "\n",
    "<blockquote>\n",
    "    \n",
    "有一个**局面（state）**，4x4格子上的一些数字。\n",
    "    \n",
    "<img src=\"https://data.megengine.org.cn/megstudio/images/2048_demo.png\" width=256 height=256 />\n",
    "\n",
    "你可以选择做一些**动作（action）**，比如按键盘上的上/下/左/右键。\n",
    "\n",
    "你有一些**策略（policy）**，比如你觉得现在按左最好，因为这样有两个8可以合并。对于每个动作，可以用一个打分函数来决定你的策略。\n",
    "\n",
    "在按照策略做完动作之后，你会得到一个**奖励（reward）**，比如因为两个8合并，分数增加了16，这个16可以被看作是这一步的奖励。\n",
    "\n",
    "在许多步之后，游戏结束，你会得到一个**回报（return）**，即游戏的最终分数。\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "由此，我们将2048建模为一个马尔可夫决策过程，其求解可以通过各种强化学习方法来完成。在baseline中，我们使用了 [Double DQN](https://arxiv.org/abs/1509.06461)。\n",
    "\n",
    "### 任务：\n",
    "\n",
    "Q1：训练模型\n",
    "\n",
    "运行baseline，训练和评估模型。观察游戏结束时的滑动平均分数。你可以调用`print_grid`函数输出模型玩游戏的过程，以判断模型是否可以得到合理的结果。\n",
    "提供参考数据：纯随机游玩，平均分数约为570分。在baseline的训练过程中，模型最高可以达到8000分，平均为2000分左右。\n",
    "\n",
    "请你修改参数，模型结构等，使得游戏的平均分数尽可能地高。请注意：这里的平均分数指每个游戏结束**最终分数**的平均值。\n",
    "**请于q1.diff提交你的代码。**\n",
    "\n",
    "## 数据集\n",
    "\n",
    "2048游戏代码来源：[console2048](https://github.com/Mekire/console-2048/blob/master/console2048.py)\n",
    "\n",
    "## 文件存储\n",
    "实验中生成的文件可以存储于 workspace 目录中。 查看工作区文件，该目录下的变更将会持久保存。 您的所有项目将共享一个存储空间，请及时清理不必要的文件，避免加载过慢。\n",
    "\n",
    "## 实验步骤\n",
    "\n",
    "1.导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import megengine as mge\n",
    "import numpy as np \n",
    "import megengine.module as M\n",
    "import megengine.functional as F\n",
    "import megengine.data.transform as T\n",
    "from random import randint, shuffle\n",
    "from megengine.optimizer import Adam\n",
    "from megengine.autodiff import GradManager\n",
    "from megengine import tensor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2048游戏函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Mekire/console-2048/blob/master/console2048.py\n",
    "# 此处定义了2048的游戏函数\n",
    "# api主要有两种调用方式，第一种就是使用类Game\n",
    "# 第二种就是使用函数push(np_array, direction)。但是这种方法一定要注意的是，由于传入np_array类似传入了一个指针。\n",
    "# 执行完毕之后，返回值和传入的np_array共用一个地址。所以除非np_array传入之后，就不再使用，否则应该先拷贝一份：\n",
    "# np_copy = np_array.copy()\n",
    "# next_state = push(np_copy, direction)\n",
    "\n",
    "def push_left(grid):\n",
    "    moved, score = False, 0\n",
    "    rows, columns = grid.shape[0], grid.shape[1]\n",
    "    for k in range(rows):\n",
    "        i, last = 0, 0\n",
    "        for j in range(columns):\n",
    "            e = grid[k, j]\n",
    "            if e:\n",
    "                if e == last:\n",
    "                    grid[k, i-1]+=e\n",
    "                    score += e\n",
    "                    last, moved = 0, True\n",
    "                else:\n",
    "                    moved |= (i != j)\n",
    "                    last=grid[k, i]=e\n",
    "                    i+=1\n",
    "        while i<columns:\n",
    "            grid[k,i]=0\n",
    "            i+=1\n",
    "    return score if moved else -1\n",
    "\n",
    "\n",
    "def push_right(grid):\n",
    "    moved, score = False, 0\n",
    "    rows, columns = grid.shape[0], grid.shape[1]\n",
    "    for k in range(rows):\n",
    "        i = columns-1\n",
    "        last  = 0\n",
    "        for j in range(columns-1,-1,-1):\n",
    "            e = grid[k, j]\n",
    "            if e:\n",
    "                if e == last:\n",
    "                    grid[k, i+1]+=e\n",
    "                    score += e\n",
    "                    last, moved = 0, True\n",
    "                else:\n",
    "                    moved |= (i != j)\n",
    "                    last=grid[k, i]=e\n",
    "                    i-=1\n",
    "        while 0<=i:\n",
    "            grid[k, i]=0\n",
    "            i-=1\n",
    "    return score if moved else -1\n",
    "\n",
    "\n",
    "def push_up(grid):\n",
    "    moved,score = False, 0\n",
    "    rows, columns = grid.shape[0], grid.shape[1]\n",
    "    for k in range(columns):\n",
    "        i, last = 0, 0\n",
    "        for j in range(rows):\n",
    "            e = grid[j, k]\n",
    "            if e:\n",
    "                if e == last:\n",
    "                    score += e\n",
    "                    grid[i-1, k]+=e\n",
    "                    last, moved = 0, True\n",
    "                else:\n",
    "                    moved |= (i != j)\n",
    "                    last=grid[i, k]=e\n",
    "                    i+=1\n",
    "        while i<rows:\n",
    "            grid[i, k]=0\n",
    "            i+=1\n",
    "    return score if moved else -1\n",
    "\n",
    "def push_down(grid):\n",
    "    moved, score = False, 0\n",
    "    rows, columns = grid.shape[0], grid.shape[1]\n",
    "    for k in range(columns):\n",
    "        i, last = rows-1, 0\n",
    "        for j in range(rows-1,-1,-1):\n",
    "            e = grid[j, k]\n",
    "            if e:\n",
    "                if e == last:\n",
    "                    score += e\n",
    "                    grid[i+1, k]+=e\n",
    "                    last, moved = 0, True\n",
    "                else:\n",
    "                    moved |= (i != j)\n",
    "                    last=grid[i, k]=e\n",
    "                    i-=1\n",
    "        while 0<=i:\n",
    "            grid[i, k]=0\n",
    "            i-=1\n",
    "    return score if moved else -1\n",
    "\n",
    "\n",
    "def push(grid, direction):\n",
    "    if direction&1:\n",
    "        if direction&2:\n",
    "            score = push_down(grid)\n",
    "        else:\n",
    "            score = push_up(grid)\n",
    "    else:\n",
    "        if direction&2:\n",
    "            score = push_right(grid)\n",
    "        else:\n",
    "            score = push_left(grid)\n",
    "    return score\n",
    "\n",
    "\n",
    "def put_new_cell(grid):\n",
    "    n = 0\n",
    "    r = 0\n",
    "    i_s=[0]*16\n",
    "    j_s=[0]*16\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(grid.shape[1]):\n",
    "            if not grid[i,j]:\n",
    "                i_s[n]=i\n",
    "                j_s[n]=j\n",
    "                n+=1\n",
    "    if n > 0:\n",
    "        r = randint(0, n-1)\n",
    "        grid[i_s[r], j_s[r]] = 2 if random.random() < 0.9 else 4\n",
    "    return n\n",
    "\n",
    "def any_possible_moves(grid):\n",
    "    \"\"\"Return True if there are any legal moves, and False otherwise.\"\"\"\n",
    "    rows = grid.shape[0]\n",
    "    columns = grid.shape[1]\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            e = grid[i, j]\n",
    "            if not e:\n",
    "                return True\n",
    "            if j and e == grid[i, j-1]:\n",
    "                return True\n",
    "            if i and e == grid[i-1, j]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def prepare_next_turn(grid):\n",
    "    \"\"\"\n",
    "    Spawn a new number on the grid; then return the result of\n",
    "    any_possible_moves after this change has been made.\n",
    "    \"\"\"\n",
    "    empties = put_new_cell(grid)\n",
    "    return empties>1 or any_possible_moves(grid)\n",
    "\n",
    "\n",
    "def print_grid(grid_array):\n",
    "    \"\"\"Print a pretty grid to the screen.\"\"\"\n",
    "    print(\"\")\n",
    "    wall = \"+------\"*grid_array.shape[1]+\"+\"\n",
    "    print(wall)\n",
    "    for i in range(grid_array.shape[0]):\n",
    "        meat = \"|\".join(\"{:^6}\".format(grid_array[i, j]) for j in range(grid_array.shape[1]))\n",
    "        print(\"|{}|\".format(meat))\n",
    "        print(wall)\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, cols=4, rows=4):\n",
    "        self.grid_array = np.zeros(shape=(rows, cols), dtype='uint16')\n",
    "        self.grid = self.grid_array\n",
    "        for i in range(2):\n",
    "            put_new_cell(self.grid)\n",
    "        self.score = 0\n",
    "        self.end = False\n",
    "\n",
    "    def copy(self):\n",
    "        rtn = Game(self.grid.shape[0], self.grid.shape[1])\n",
    "        for i in range(self.grid.shape[0]):\n",
    "            for j in range(self.grid.shape[1]):\n",
    "                rtn.grid[i,j]=self.grid[i,j]\n",
    "        rtn.score = self.score\n",
    "        rtn.end = self.end\n",
    "        return rtn\n",
    "\n",
    "    def max(self):\n",
    "        m = 0\n",
    "        for i in range(self.grid.shape[0]):\n",
    "            for j in range(self.grid.shape[1]):\n",
    "                if self.grid[i,j]>m:\n",
    "                    m = self.grid[i,j]\n",
    "        return m\n",
    "\n",
    "    def move(self, direction):\n",
    "        if direction & 1:\n",
    "            if direction & 2:\n",
    "                score = push_down(self.grid)  # 3\n",
    "            else:\n",
    "                score = push_up(self.grid)  # 1\n",
    "        else:\n",
    "            if direction & 2:\n",
    "                score = push_right(self.grid)  # 2\n",
    "            else:\n",
    "                score = push_left(self.grid)  # 0\n",
    "        if score == -1:\n",
    "            return 0\n",
    "        self.score += score\n",
    "        if not prepare_next_turn(self.grid):\n",
    "            self.end = True\n",
    "        return 1\n",
    "\n",
    "    def display(self):\n",
    "        print_grid(self.grid_array)\n",
    "\n",
    "\n",
    "def random_play(game):\n",
    "    moves = [0, 1, 2, 3]\n",
    "    while not game.end:\n",
    "        shuffle(moves)\n",
    "        for m in moves:\n",
    "            if game.move(m):\n",
    "                break\n",
    "    return game.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.定义记忆回放类并实例化\n",
    "\n",
    "在记录一次决策过程后，我们存储到该类中，并在训练时选择一部分记忆进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/megvii-research/ICCV2019-LearningToPaint/blob/master/baseline/DRL/rpm.py\n",
    "# 这个就是一个缓存区，目的就是记录训练过程中的样本。\n",
    "# 里面记录的元素为：(status, next_status, action, score, if_game_over)\n",
    "# 它设置了一个缓冲区大小，默认为5000，大概就是先进先出的队列模式\n",
    "\n",
    "class rpm(object):\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = []\n",
    "        self.index = 0\n",
    "\n",
    "    def append(self, obj):\n",
    "        if self.size() > self.buffer_size:\n",
    "            print('buffer size larger than set value, trimming...')\n",
    "            self.buffer = self.buffer[(self.size() - self.buffer_size):]\n",
    "        elif self.size() == self.buffer_size:\n",
    "            self.buffer[self.index] = obj\n",
    "            self.index += 1\n",
    "            self.index %= self.buffer_size\n",
    "        else:\n",
    "            self.buffer.append(obj)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        if self.size() < batch_size:\n",
    "            batch = random.sample(self.buffer, self.size())\n",
    "        else:\n",
    "            batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        res = []\n",
    "        for i in range(5):\n",
    "            k = F.stack(tuple(item[i] for item in batch), axis=0)\n",
    "            res.append(k)\n",
    "        return res[0], res[1], res[2], res[3], res[4]\n",
    "\n",
    "\n",
    "data = rpm(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.定义模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m20 01:07:59[mgb] \u001b[0m\u001b[1;31mWRN cuda unavailable: CUDA driver version is insufficient for CUDA runtime version(35) ndev=-1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class Net(M.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv0 = M.Conv2d(16, 256, kernel_size=(2, 1), stride=1, padding=0)\n",
    "        self.relu0 = M.ReLU()\n",
    "        self.conv1 = M.Conv2d(256, 256, kernel_size=(1, 2), stride=1, padding=0)\n",
    "        self.relu1 = M.ReLU()\n",
    "        self.conv2 = M.Conv2d(256, 256, kernel_size=(2, 1), stride=1, padding=0)\n",
    "        self.relu2 = M.ReLU()\n",
    "        self.conv3 = M.Conv2d(256, 256, kernel_size=(1, 2), stride=1, padding=0)\n",
    "        self.relu3 = M.ReLU()\n",
    "        self.fc1 = M.Linear(1024, 16)\n",
    "        self.relu5 = M.ReLU()\n",
    "        self.fc2 = M.Linear(16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = F.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.reshape(x, (-1, 4))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model_target = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.定义输入转化函数，使得局面可以被输入进模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数make_input实际上进行了这样一个转化：\n",
    "# 输入时一个（4*4）的np_array。\n",
    "# 然后输出的是一个（16*4*4）的tensor。这个tensor和np_array的对应关系是：\n",
    "# 如果np_array[i][j] = k\n",
    "# 那么tensor[value][i][j] = 1，其它位置为0\n",
    "# 其中value = table[k] ------- table的含义看下面\n",
    "\n",
    "table = {2**i: i for i in range(1, 16)}\n",
    "table[0] = 0\n",
    "\n",
    "\n",
    "def make_input(grid):\n",
    "    g0 = grid\n",
    "    r = np.zeros(shape=(16, 4, 4), dtype=np.float32)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            v = g0[i, j]\n",
    "            r[table[v], i, j] = 1\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 21/50000 [00:08<5:20:55,  2.60it/s, loss=0.00040, Q=0.07053, reward=1.31250, avg_score=0.00000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5d308ea095ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 tq.set_postfix(\n\u001b[1;32m    102\u001b[0m                             {\n\u001b[0;32m--> 103\u001b[0;31m                                 \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{0:1.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                                 \u001b[0;34m\"Q\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{0:1.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_Q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                                 \u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{0:1.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda/envs/xuan/lib/python3.7/site-packages/megengine/tensor.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maxscore = 0\n",
    "avg_score = 0\n",
    "epochs = 10000\n",
    "\n",
    "game = []\n",
    "Game()\n",
    "'''Play 32 games at the same time'''\n",
    "# 因为要使用神经网络计算，就要充分利用batch这个维度，因此就要同时玩32盘。这样batch=32\n",
    "for i in range(32):\n",
    "    game.append(Game())\n",
    "\n",
    "with tqdm(total=epochs * 5, desc=\"epoch\") as tq:\n",
    "    for epoch in range(epochs):\n",
    "        '''double DQN'''\n",
    "        # 每隔10个epoch更新一次固定参数的model\n",
    "        if epoch % 10 == 0:\n",
    "            mge.save(model, \"1.mge\")\n",
    "            model_target = mge.load(\"1.mge\")\n",
    "\n",
    "        # prepare input for NN, check whether the game is over\n",
    "        # evaluate the avg score\n",
    "        grid = []\n",
    "        for k in range(32):\n",
    "            '''Check if the game is over'''\n",
    "            # 判断游戏结束的标准是：没有可能的移动方案了\n",
    "            # 如果游戏结束，则更新分数平均值，并且重新开一局\n",
    "            if not any_possible_moves(game[k].grid):\n",
    "                if avg_score == 0:\n",
    "                    avg_score = game[k].score\n",
    "                else:\n",
    "                    avg_score = avg_score * 0.99 + game[k].score * 0.01\n",
    "                game[k] = Game()\n",
    "\n",
    "            # 把所有的当前状态make_input，然后添加到grid里面保存。\n",
    "            # status指的就是所有的32盘游戏状态叠起来，形状为(32, 16, 4, 4), 作为神经网络的输入\n",
    "            tmp = make_input(game[k].grid)\n",
    "            grid.append(tensor(tmp))\n",
    "\n",
    "        status = F.stack(grid, 0)\n",
    "\n",
    "        '''Choose the action with the highest probability'''\n",
    "        # 选出得分最高的动作a\n",
    "        # a的形状为(32, 1)，其中的每一个元素都属于{0, 1, 2, 3}。含义是32盘游戏中，每盘游戏的最佳动作\n",
    "        a = F.argmax(model(status).detach(), 1)\n",
    "        a = a.numpy()\n",
    "\n",
    "        # 这一步的主要工作是记录下状态转移前后的各种变化，并且存储到缓冲区rpn里面，比较简单就不解释了\n",
    "        for k in range(32):\n",
    "            pre_score = game[k].score\n",
    "            pre_grid = game[k].grid.copy()\n",
    "            game[k].move(a[k])\n",
    "            after_score = game[k].score\n",
    "            if game[k].score > maxscore:\n",
    "                maxscore = game[k].score\n",
    "            action = a[k]\n",
    "\n",
    "            '''In some situations, some actions are meaningless, try another'''\n",
    "            while (game[k].grid == pre_grid).all():\n",
    "                action = (action + 1) % 4\n",
    "                game[k].move(action)\n",
    "                after_score = game[k].score\n",
    "\n",
    "            score = after_score - pre_score\n",
    "            done = tensor(any_possible_moves(game[k].grid) == False)\n",
    "            grid = tensor(make_input(game[k].grid.copy()))\n",
    "\n",
    "            '''Record to memory'''\n",
    "            '''(status, next_status, action, score, if_game_over)'''\n",
    "            data.append((tensor(make_input(pre_grid)), tensor(grid), tensor(a[k]), tensor(score / 128), done))\n",
    "\n",
    "        # 核心的训练步骤\n",
    "        # 对样本采样5次\n",
    "        # 总共对5 * 32个样本进行拟合\n",
    "        for i in range(5):\n",
    "            # 设定优化器，指定要优化的模型是model,而不是model_target。model_target就作为一个固定权重的网络了。\n",
    "            gm = GradManager().attach(model.parameters())\n",
    "            with gm:\n",
    "                # 从缓冲区里面随机抽取32条记录进行训练\n",
    "                s0, s1, a, reward, d = data.sample_batch(32)\n",
    "\n",
    "                '''double DQN'''\n",
    "                # 从这里开始到tq前面，就是核心的更新策略\n",
    "                # DQN的更新公式就是：Q(s, a) = Q(s, a) + alpha * (max{Q(s', a)} + reward - Q(s, a))   ---- 当游戏没结束时\n",
    "                # Q(s, a) = Q(s, a) + alpha * (reward - Q(s, a))   ---- 当游戏结束\n",
    "                # 这个公式就体现在loss += F.loss.square_loss(Q, pred_s1[i].detach() * 0.99 * (1 - d[i]) + reward[i])\n",
    "                pred_s0 = model(s0)  # Q(s, a)\n",
    "                pred_s1 = F.max(model_target(s1), axis=1)  # max{Q(s', a)}\n",
    "\n",
    "                loss = 0\n",
    "                total_Q = 0\n",
    "                total_reward = 0\n",
    "                for i in range(32):\n",
    "                    Q = pred_s0[i][a[i]]\n",
    "                    total_Q += Q\n",
    "                    total_reward += reward[i]\n",
    "                    loss += F.loss.square_loss(Q, pred_s1[i].detach() * 0.99 * (1 - d[i]) + reward[i])\n",
    "                loss /= 32\n",
    "                total_Q /= 32\n",
    "                total_reward = total_reward / 32 * 128\n",
    "\n",
    "                # 显示运行中间结果\n",
    "                tq.set_postfix(\n",
    "                            {\n",
    "                                \"loss\": \"{0:1.5f}\".format(loss.numpy().item()),\n",
    "                                \"Q\": \"{0:1.5f}\".format(total_Q.numpy().item()),\n",
    "                                \"reward\": \"{0:1.5f}\".format(total_reward.numpy().item()),\n",
    "                                \"avg_score\": \"{0:1.5f}\".format(avg_score),\n",
    "                            }\n",
    "                        )\n",
    "                tq.update(1)\n",
    "                # 梯度反传\n",
    "                # 优化器更新\n",
    "                gm.backward(loss)\n",
    "\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "print(\"maxscore:{}\".format(maxscore))\n",
    "print(\"avg_score:{}\".format(avg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
